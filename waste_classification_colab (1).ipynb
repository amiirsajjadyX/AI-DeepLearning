{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# طبقه‌بندی زباله با شبکه عصبی کانولوشنی (CNN)\n",
    "## Waste Classification using Custom CNN\n",
    "\n",
    "این نوت‌بوک یک مدل CNN سفارشی (بدون استفاده از Transfer Learning) برای طبقه‌بندی زباله‌ها به **چهار دسته** می‌سازد:\n",
    "\n",
    "| کلاس | Class | توضیح |\n",
    "|-------|-------|-------|\n",
    "| پلاستیک | Plastic | بطری، کیسه، ظروف پلاستیکی |\n",
    "| کاغذ | Paper | روزنامه، مقوا، اسناد |\n",
    "| فلز | Metal | قوطی، فویل، ظروف فلزی |\n",
    "| آلی | Organic | پسماند غذایی، گیاهان، مواد تجزیه‌پذیر |\n",
    "\n",
    "### ویژگی‌ها:\n",
    "- مدل CNN سفارشی از صفر (بدون مدل از پیش آموزش‌دیده)\n",
    "- دیتاست TrashNet از GitHub\n",
    "- Data Augmentation قوی\n",
    "- ارزیابی کامل با Confusion Matrix و Classification Report\n",
    "- اپلیکیشن وب Flask با رابط فارسی برای تست با دوربین گوشی\n",
    "\n",
    "> **نکته:** برای آموزش سریع‌تر، از Runtime > Change runtime type > GPU استفاده کنید."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n## ۱. نصب کتابخانه‌ها و بررسی GPU",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# وارد کردن کتابخانه‌ها\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.regularizers import l2\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport shutil\nimport glob\nimport json\nimport random\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# بررسی نسخه تنسورفلو و GPU\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n\n# فعال‌سازی رشد حافظه GPU\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    for gpu in gpus:\n        tf.config.experimental.set_memory_growth(gpu, True)\n    print(\"GPU memory growth enabled\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## ۲. دانلود دیتاست TrashNet از GitHub\n\nدیتاست TrashNet شامل تصاویر زباله در ۶ دسته است. ما آن را مستقیماً از GitHub دانلود می‌کنیم (بدون نیاز به Kaggle API).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# پاک کردن فایل‌های قبلی\n!rm -rf dataset-resized* waste_dataset 2>/dev/null\n\n# دانلود مستقیم دیتاست از GitHub\n!wget -q https://github.com/garythung/trashnet/raw/master/data/dataset-resized.zip -O dataset-resized.zip\n\n# استخراج فایل zip\n!unzip -q dataset-resized.zip\n\n# بررسی محتویات\n!ls -la dataset-resized/",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# تنظیم مسیر دیتاست\nif os.path.exists('dataset-resized'):\n    dataset_path = 'dataset-resized'\nelse:\n    for root, dirs, files in os.walk('.'):\n        if 'plastic' in dirs and 'paper' in dirs:\n            dataset_path = root\n            break\n    else:\n        raise FileNotFoundError(\"دیتاست پیدا نشد!\")\n\nprint(f\"مسیر دیتاست: {dataset_path}\")\n\n# بررسی ساختار دیتاست و تعداد تصاویر\nprint(\"\\n=== ساختار دیتاست ===\")\ntotal_images = 0\nfor folder in sorted(os.listdir(dataset_path)):\n    folder_path = os.path.join(dataset_path, folder)\n    if os.path.isdir(folder_path):\n        count = len([f for f in os.listdir(folder_path)\n                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n        total_images += count\n        print(f\"  {folder}: {count} تصویر\")\nprint(f\"\\nمجموع: {total_images} تصویر\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## ۳. آماده‌سازی و تقسیم داده‌ها\n\nدیتاست TrashNet شامل ۶ کلاس است. ما آن‌ها را به ۴ کلاس نگاشت می‌کنیم:\n\n| کلاس اصلی | کلاس هدف | توضیح |\n|------------|----------|-------|\n| plastic | plastic | پلاستیک |\n| paper | paper | کاغذ |\n| metal | metal | فلز |\n| cardboard | organic | مقوا → آلی |\n| trash | organic | زباله عمومی → آلی |\n| glass | - | حذف می‌شود |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ایجاد پوشه‌های جدید برای ۴ کلاس\nnew_dataset_path = 'waste_dataset'\ncategories = ['plastic', 'paper', 'metal', 'organic']\n\n# پاک کردن پوشه قبلی اگر وجود دارد\nif os.path.exists(new_dataset_path):\n    shutil.rmtree(new_dataset_path)\n\n# ایجاد ساختار پوشه: train, val, test\nfor split in ['train', 'val', 'test']:\n    for cat in categories:\n        os.makedirs(os.path.join(new_dataset_path, split, cat), exist_ok=True)\n\n# نگاشت کلاس‌های TrashNet به ۴ کلاس ما\nclass_mapping = {\n    'plastic': 'plastic',\n    'paper': 'paper',\n    'metal': 'metal',\n    'cardboard': 'organic',\n    'trash': 'organic'\n    # glass حذف می‌شود چون در ۴ کلاس ما نیست\n}\n\n# جمع‌آوری و تقسیم داده‌ها\nfor original_class, target_class in class_mapping.items():\n    source_folder = os.path.join(dataset_path, original_class)\n    if not os.path.exists(source_folder):\n        print(f\"پوشه '{original_class}' پیدا نشد، رد شد...\")\n        continue\n\n    # پیدا کردن همه تصاویر\n    images = glob.glob(os.path.join(source_folder, '*.jpg')) + \\\n             glob.glob(os.path.join(source_folder, '*.jpeg')) + \\\n             glob.glob(os.path.join(source_folder, '*.png'))\n\n    if len(images) == 0:\n        print(f\"تصویری در '{original_class}' پیدا نشد\")\n        continue\n\n    # تقسیم: 70% train, 15% val, 15% test\n    train_imgs, temp_imgs = train_test_split(images, test_size=0.3, random_state=42)\n    val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.5, random_state=42)\n\n    # کپی فایل‌ها با نام یکتا\n    for i, img in enumerate(train_imgs):\n        ext = os.path.splitext(img)[1]\n        shutil.copy(img, os.path.join(new_dataset_path, 'train', target_class, f\"{original_class}_{i}{ext}\"))\n\n    for i, img in enumerate(val_imgs):\n        ext = os.path.splitext(img)[1]\n        shutil.copy(img, os.path.join(new_dataset_path, 'val', target_class, f\"{original_class}_{i}{ext}\"))\n\n    for i, img in enumerate(test_imgs):\n        ext = os.path.splitext(img)[1]\n        shutil.copy(img, os.path.join(new_dataset_path, 'test', target_class, f\"{original_class}_{i}{ext}\"))\n\n    print(f\"{original_class} -> {target_class}: train={len(train_imgs)}, val={len(val_imgs)}, test={len(test_imgs)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# آمار نهایی دیتاست\nprint(\"=\" * 50)\nprint(\"آمار نهایی دیتاست\")\nprint(\"=\" * 50)\nfor split in ['train', 'val', 'test']:\n    print(f\"\\n{split.upper()}:\")\n    total = 0\n    for cat in categories:\n        path = os.path.join(new_dataset_path, split, cat)\n        count = len(os.listdir(path)) if os.path.exists(path) else 0\n        total += count\n        print(f\"  {cat}: {count} تصویر\")\n    print(f\"  مجموع: {total} تصویر\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## ۴. افزایش داده (Data Augmentation) و ایجاد Generator",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# پارامترها\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32\n\n# Data Augmentation برای آموزش\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='nearest'\n)\n\n# فقط نرمال‌سازی برای اعتبارسنجی و تست\nval_test_datagen = ImageDataGenerator(rescale=1./255)\n\n# ایجاد Generator ها\ntrain_generator = train_datagen.flow_from_directory(\n    os.path.join(new_dataset_path, 'train'),\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True\n)\n\nval_generator = val_test_datagen.flow_from_directory(\n    os.path.join(new_dataset_path, 'val'),\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=False\n)\n\ntest_generator = val_test_datagen.flow_from_directory(\n    os.path.join(new_dataset_path, 'test'),\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=False\n)\n\n# نمایش اطلاعات کلاس‌ها\nclass_names = list(train_generator.class_indices.keys())\nnum_classes = len(class_names)\nprint(f\"\\nکلاس‌ها: {class_names}\")\nprint(f\"تعداد کلاس‌ها: {num_classes}\")\nprint(f\"اندیس کلاس‌ها: {train_generator.class_indices}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# نمایش نمونه تصاویر افزایش‌یافته\nimages, labels = next(train_generator)\n\nplt.figure(figsize=(16, 8))\nfor i in range(min(8, len(images))):\n    plt.subplot(2, 4, i + 1)\n    plt.imshow(images[i])\n    label_idx = np.argmax(labels[i])\n    plt.title(f'{class_names[label_idx]}', fontsize=12)\n    plt.axis('off')\nplt.suptitle('نمونه تصاویر آموزشی (با Data Augmentation)', fontsize=14)\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## ۵. ساخت مدل CNN سفارشی\n\nمدل CNN ما شامل ۵ بلوک کانولوشنی با فیلترهای افزایشی (۳۲ → ۶۴ → ۱۲۸ → ۲۵۶ → ۵۱۲) است.\n\n### معماری مدل:\n- **بلوک‌های کانولوشنی:** هر بلوک شامل دو لایه Conv2D + BatchNormalization + ReLU + MaxPooling + Dropout\n- **Global Average Pooling:** به جای Flatten برای کاهش پارامترها\n- **لایه‌های Dense:** ۵۱۲ → ۲۵۶ → ۴ (softmax)\n- **Regularization:** L2 روی تمام لایه‌ها + Dropout + BatchNormalization",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def build_cnn_model(input_shape=(224, 224, 3), num_classes=4):\n    \"\"\"\n    ساخت مدل CNN سفارشی برای طبقه‌بندی زباله\n    این مدل از صفر ساخته شده و از هیچ مدل از پیش آموزش‌دیده‌ای استفاده نمی‌کند\n    \"\"\"\n    model = models.Sequential([\n        # === بلوک ۱: ۳۲ فیلتر ===\n        layers.Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(0.001),\n                      input_shape=input_shape),\n        layers.BatchNormalization(),\n        layers.Activation('relu'),\n        layers.Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(0.001)),\n        layers.BatchNormalization(),\n        layers.Activation('relu'),\n        layers.MaxPooling2D((2, 2)),\n        layers.Dropout(0.25),\n\n        # === بلوک ۲: ۶۴ فیلتر ===\n        layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(0.001)),\n        layers.BatchNormalization(),\n        layers.Activation('relu'),\n        layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(0.001)),\n        layers.BatchNormalization(),\n        layers.Activation('relu'),\n        layers.MaxPooling2D((2, 2)),\n        layers.Dropout(0.25),\n\n        # === بلوک ۳: ۱۲۸ فیلتر ===\n        layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2(0.001)),\n        layers.BatchNormalization(),\n        layers.Activation('relu'),\n        layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2(0.001)),\n        layers.BatchNormalization(),\n        layers.Activation('relu'),\n        layers.MaxPooling2D((2, 2)),\n        layers.Dropout(0.25),\n\n        # === بلوک ۴: ۲۵۶ فیلتر ===\n        layers.Conv2D(256, (3, 3), padding='same', kernel_regularizer=l2(0.001)),\n        layers.BatchNormalization(),\n        layers.Activation('relu'),\n        layers.Conv2D(256, (3, 3), padding='same', kernel_regularizer=l2(0.001)),\n        layers.BatchNormalization(),\n        layers.Activation('relu'),\n        layers.MaxPooling2D((2, 2)),\n        layers.Dropout(0.25),\n\n        # === بلوک ۵: ۵۱۲ فیلتر ===\n        layers.Conv2D(512, (3, 3), padding='same', kernel_regularizer=l2(0.001)),\n        layers.BatchNormalization(),\n        layers.Activation('relu'),\n\n        # === Global Average Pooling ===\n        layers.GlobalAveragePooling2D(),\n\n        # === لایه‌های Fully Connected ===\n        layers.Dense(512, kernel_regularizer=l2(0.001)),\n        layers.BatchNormalization(),\n        layers.Activation('relu'),\n        layers.Dropout(0.5),\n\n        layers.Dense(256, kernel_regularizer=l2(0.001)),\n        layers.BatchNormalization(),\n        layers.Activation('relu'),\n        layers.Dropout(0.3),\n\n        # === لایه خروجی ===\n        layers.Dense(num_classes, activation='softmax')\n    ])\n\n    return model\n\n# ساخت مدل\nmodel = build_cnn_model(num_classes=num_classes)\nmodel.summary()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# کامپایل مدل\nmodel.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nprint(\"مدل با موفقیت کامپایل شد!\")\nprint(f\"تعداد کل پارامترها: {model.count_params():,}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## ۶. آموزش مدل\n\nاز Callback های زیر استفاده می‌کنیم:\n- **EarlyStopping:** توقف زودهنگام در صورت عدم بهبود (صبر: ۱۵ epoch)\n- **ModelCheckpoint:** ذخیره بهترین مدل بر اساس دقت اعتبارسنجی\n- **ReduceLROnPlateau:** کاهش نرخ یادگیری در صورت عدم بهبود",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# تعریف Callback ها\ncallbacks = [\n    EarlyStopping(\n        monitor='val_loss',\n        patience=15,\n        restore_best_weights=True,\n        verbose=1\n    ),\n    ModelCheckpoint(\n        'best_waste_classifier.keras',\n        monitor='val_accuracy',\n        save_best_only=True,\n        verbose=1\n    ),\n    ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.5,\n        patience=5,\n        min_lr=1e-7,\n        verbose=1\n    )\n]\n\n# آموزش مدل\nEPOCHS = 50\n\nprint(\"شروع آموزش...\")\nprint(f\"تعداد نمونه‌های آموزشی: {train_generator.samples}\")\nprint(f\"تعداد نمونه‌های اعتبارسنجی: {val_generator.samples}\")\nprint(f\"تعداد epoch ها: {EPOCHS}\")\nprint(\"=\" * 50)\n\nhistory = model.fit(\n    train_generator,\n    epochs=EPOCHS,\n    validation_data=val_generator,\n    callbacks=callbacks,\n    verbose=1\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## ۷. نمایش نتایج آموزش (نمودار Accuracy و Loss)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# رسم نمودار Accuracy و Loss\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# نمودار دقت\naxes[0].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2, color='blue')\naxes[0].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2, color='orange')\naxes[0].set_title('دقت مدل (Accuracy)', fontsize=14)\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Accuracy')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# نمودار خطا\naxes[1].plot(history.history['loss'], label='Train Loss', linewidth=2, color='blue')\naxes[1].plot(history.history['val_loss'], label='Val Loss', linewidth=2, color='orange')\naxes[1].set_title('خطای مدل (Loss)', fontsize=14)\naxes[1].set_xlabel('Epoch')\naxes[1].set_ylabel('Loss')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('training_history.png', dpi=150)\nplt.show()\n\n# بهترین نتایج\nbest_val_acc = max(history.history['val_accuracy'])\nbest_epoch = history.history['val_accuracy'].index(best_val_acc) + 1\nprint(f\"\\nبهترین دقت اعتبارسنجی: {best_val_acc*100:.2f}% در epoch {best_epoch}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## ۸. ارزیابی مدل روی داده‌های تست",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# بارگذاری بهترین مدل\nbest_model = keras.models.load_model('best_waste_classifier.keras')\nprint(\"بهترین مدل بارگذاری شد!\")\n\n# ارزیابی روی داده تست\nprint(\"\\nارزیابی روی داده‌های تست...\")\ntest_loss, test_accuracy = best_model.evaluate(test_generator, verbose=1)\nprint(f\"\\n{'='*50}\")\nprint(f\"دقت تست: {test_accuracy*100:.2f}%\")\nprint(f\"خطای تست: {test_loss:.4f}\")\nprint(f\"{'='*50}\")\n\n# پیش‌بینی روی داده‌های تست\ntest_generator.reset()\npredictions = best_model.predict(test_generator, verbose=1)\npredicted_classes = np.argmax(predictions, axis=1)\ntrue_classes = test_generator.classes\n\n# گزارش طبقه‌بندی\nprint(f\"\\n{'='*50}\")\nprint(\"گزارش طبقه‌بندی (Classification Report)\")\nprint(f\"{'='*50}\")\nprint(classification_report(true_classes, predicted_classes, target_names=class_names))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ماتریس درهم‌ریختگی (Confusion Matrix)\ncm = confusion_matrix(true_classes, predicted_classes)\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=class_names, yticklabels=class_names,\n            annot_kws={'size': 14})\nplt.title('ماتریس درهم‌ریختگی (Confusion Matrix)', fontsize=16)\nplt.xlabel('برچسب پیش‌بینی شده', fontsize=12)\nplt.ylabel('برچسب واقعی', fontsize=12)\nplt.tight_layout()\nplt.savefig('confusion_matrix.png', dpi=150)\nplt.show()\n\n# دقت هر کلاس\nprint(\"\\nدقت هر کلاس:\")\nfor i, name in enumerate(class_names):\n    class_acc = cm[i, i] / cm[i].sum() * 100 if cm[i].sum() > 0 else 0\n    print(f\"  {name}: {class_acc:.2f}%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## ۹. نمایش پیش‌بینی‌های مدل",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# نمایش تصاویر با پیش‌بینی و برچسب واقعی\ntest_generator.reset()\nimages, labels = next(test_generator)\npreds = best_model.predict(images, verbose=0)\n\nplt.figure(figsize=(16, 12))\nfor i in range(min(12, len(images))):\n    plt.subplot(3, 4, i + 1)\n    plt.imshow(images[i])\n\n    true_label = class_names[np.argmax(labels[i])]\n    pred_label = class_names[np.argmax(preds[i])]\n    confidence = np.max(preds[i]) * 100\n\n    color = 'green' if true_label == pred_label else 'red'\n    plt.title(f'True: {true_label}\\nPred: {pred_label} ({confidence:.1f}%)',\n              color=color, fontsize=10)\n    plt.axis('off')\n\nplt.suptitle('پیش‌بینی‌های مدل (سبز=صحیح، قرمز=غلط)', fontsize=14)\nplt.tight_layout()\nplt.savefig('predictions.png', dpi=150)\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## ۱۰. پیش‌بینی تصویر جدید\n\nتابع زیر یک تصویر دلخواه را دریافت کرده، نوع زباله را تشخیص می‌دهد و نتایج را با نمودار احتمالات نمایش می‌دهد.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from tensorflow.keras.preprocessing import image\n\ndef predict_single_image(model, img_path, class_names, img_size=(224, 224)):\n    \"\"\"پیش‌بینی کلاس یک تصویر\"\"\"\n    # بارگذاری و پیش‌پردازش تصویر\n    img = image.load_img(img_path, target_size=img_size)\n    img_array = image.img_to_array(img)\n    img_array = img_array / 255.0\n    img_array = np.expand_dims(img_array, axis=0)\n\n    # پیش‌بینی\n    predictions = model.predict(img_array, verbose=0)\n    predicted_class = class_names[np.argmax(predictions[0])]\n    confidence = np.max(predictions[0]) * 100\n\n    # نمایش نتایج\n    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n    # تصویر\n    axes[0].imshow(img)\n    axes[0].set_title(f'پیش‌بینی: {predicted_class}\\nاطمینان: {confidence:.2f}%', fontsize=14)\n    axes[0].axis('off')\n\n    # احتمالات\n    colors = ['#FF6B6B' if i == np.argmax(predictions[0]) else '#4ECDC4'\n              for i in range(len(class_names))]\n    bars = axes[1].barh(class_names, predictions[0] * 100, color=colors)\n    axes[1].set_xlabel('احتمال (%)', fontsize=12)\n    axes[1].set_title('احتمال هر کلاس', fontsize=14)\n    axes[1].set_xlim(0, 100)\n\n    for bar, prob in zip(bars, predictions[0]):\n        axes[1].text(prob * 100 + 1, bar.get_y() + bar.get_height() / 2,\n                     f'{prob*100:.1f}%', va='center', fontsize=10)\n\n    plt.tight_layout()\n    plt.show()\n\n    return predicted_class, predictions[0]\n\n# تست با نمونه‌هایی از هر کلاس\nprint(\"تست با تصاویر نمونه از هر کلاس:\\n\")\nfor cat in class_names:\n    test_folder = os.path.join(new_dataset_path, 'test', cat)\n    if os.path.exists(test_folder):\n        test_images = [f for f in os.listdir(test_folder)\n                       if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n        if test_images:\n            sample_img = random.choice(test_images)\n            img_path = os.path.join(test_folder, sample_img)\n            print(f\"\\n{'='*50}\")\n            print(f\"تست تصویر {cat.upper()}: {sample_img}\")\n            print(f\"{'='*50}\")\n            pred_class, probs = predict_single_image(best_model, img_path, class_names)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# آپلود تصویر سفارشی برای پیش‌بینی (فقط در Google Colab)\ntry:\n    from google.colab import files\n\n    print(\"یک تصویر آپلود کنید:\")\n    uploaded = files.upload()\n\n    for filename in uploaded.keys():\n        print(f\"\\n{'='*50}\")\n        print(f\"طبقه‌بندی: {filename}\")\n        print(f\"{'='*50}\")\n\n        pred_class, probs = predict_single_image(best_model, filename, class_names)\n\n        print(f\"\\nنتیجه: {pred_class}\")\n        print(\"\\nاحتمالات:\")\n        for name, prob in zip(class_names, probs):\n            print(f\"  {name}: {prob*100:.2f}%\")\n\nexcept ImportError:\n    print(\"این سلول فقط در Google Colab کار می‌کند.\")\n    print(\"برای تست با تصویر سفارشی از تابع predict_single_image استفاده کنید.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## ۱۱. ذخیره و دانلود مدل",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ذخیره مدل نهایی\nbest_model.save('waste_classifier_final.keras')\nprint(\"مدل ذخیره شد: waste_classifier_final.keras\")\n\n# ذخیره نام کلاس‌ها\nwith open('class_names.json', 'w') as f:\n    json.dump(class_names, f, indent=2)\nprint(\"نام کلاس‌ها ذخیره شد: class_names.json\")\n\n# ذخیره تاریخچه آموزش\nhistory_dict = {\n    'accuracy': [float(x) for x in history.history['accuracy']],\n    'val_accuracy': [float(x) for x in history.history['val_accuracy']],\n    'loss': [float(x) for x in history.history['loss']],\n    'val_loss': [float(x) for x in history.history['val_loss']]\n}\nwith open('training_history.json', 'w') as f:\n    json.dump(history_dict, f, indent=2)\nprint(\"تاریخچه آموزش ذخیره شد: training_history.json\")\n\n# دانلود فایل‌ها (فقط در Colab)\ntry:\n    from google.colab import files as colab_files\n    print(\"\\nدانلود فایل‌ها...\")\n    for filename in ['waste_classifier_final.keras', 'best_waste_classifier.keras',\n                     'class_names.json', 'training_history.json',\n                     'training_history.png', 'confusion_matrix.png']:\n        if os.path.exists(filename):\n            colab_files.download(filename)\n            print(f\"  دانلود شد: {filename}\")\nexcept ImportError:\n    print(\"دانلود خودکار فقط در Colab کار می‌کند.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## ۱۲. اپلیکیشن وب با Flask و دوربین گوشی\n\nاین بخش یک سرور وب Flask راه‌اندازی می‌کند. با استفاده از ngrok یک لینک عمومی ایجاد می‌شود که می‌توانید از گوشی موبایل به آن وصل شوید و از دوربین گوشی برای تشخیص نوع زباله استفاده کنید.\n\n### مراحل:\n1. نصب Flask و pyngrok\n2. ایجاد فایل `app.py` (سرور Flask)\n3. ایجاد فایل `templates/index.html` (رابط کاربری فارسی)\n4. اجرای سرور و ایجاد تونل ngrok",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# نصب کتابخانه‌های مورد نیاز\n!pip install -q flask pyngrok",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%writefile app.py\n\"\"\"\nWaste Classification Web Application\nاپلیکیشن وب طبقه‌بندی زباله با استفاده از دوربین گوشی\n\"\"\"\n\nimport os\nimport json\nimport base64\nimport numpy as np\nfrom io import BytesIO\nfrom PIL import Image\nfrom flask import Flask, render_template, request, jsonify, send_file\nimport tensorflow as tf\nfrom tensorflow import keras\n\napp = Flask(__name__)\n\n# متغیرهای سراسری\nmodel = None\nclass_names = None\nMODEL_PATH = 'waste_classifier_final.keras'\nBEST_MODEL_PATH = 'best_waste_classifier.keras'\nCLASS_NAMES_PATH = 'class_names.json'\nIMG_SIZE = (224, 224)\n\n# ترجمه فارسی کلاس‌ها\nCLASS_NAMES_FA = {\n    'plastic': 'پلاستیک',\n    'paper': 'کاغذ',\n    'metal': 'فلز',\n    'organic': 'آلی'\n}\n\nRECYCLING_TIPS = {\n    'plastic': \"پلاستیک‌ها را شسته و در سطل بازیافت بیندازید.\",\n    'paper': \"کاغذها را خشک نگه دارید و در سطل بازیافت بیندازید.\",\n    'metal': \"قوطی‌های فلزی را شسته و در سطل بازیافت بیندازید.\",\n    'organic': \"زباله‌های آلی را در سطل کمپوست بیندازید.\"\n}\n\n\ndef load_model():\n    \"\"\"بارگذاری مدل و نام کلاس‌ها\"\"\"\n    global model, class_names\n\n    model_path = MODEL_PATH if os.path.exists(MODEL_PATH) else BEST_MODEL_PATH\n    if os.path.exists(model_path):\n        model = keras.models.load_model(model_path)\n        print(f\"Model loaded from {model_path}\")\n    else:\n        print(f\"Warning: Model not found at {model_path}\")\n\n    if os.path.exists(CLASS_NAMES_PATH):\n        with open(CLASS_NAMES_PATH, 'r') as f:\n            class_names = json.load(f)\n    else:\n        class_names = ['metal', 'organic', 'paper', 'plastic']\n\n\ndef preprocess_image(image_data):\n    \"\"\"پیش‌پردازش تصویر برای پیش‌بینی\"\"\"\n    if ',' in image_data:\n        image_data = image_data.split(',')[1]\n\n    image_bytes = base64.b64decode(image_data)\n    img = Image.open(BytesIO(image_bytes))\n\n    if img.mode != 'RGB':\n        img = img.convert('RGB')\n\n    img = img.resize(IMG_SIZE)\n    img_array = np.array(img) / 255.0\n    img_array = np.expand_dims(img_array, axis=0)\n    return img_array\n\n\n@app.route('/')\ndef index():\n    return render_template('index.html')\n\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n    try:\n        data = request.get_json()\n        if 'image' not in data:\n            return jsonify({'error': 'No image data'}), 400\n\n        img_array = preprocess_image(data['image'])\n        predictions = model.predict(img_array, verbose=0)\n        predicted_idx = np.argmax(predictions[0])\n        predicted_class = class_names[predicted_idx]\n        confidence = float(predictions[0][predicted_idx]) * 100\n\n        all_probs = {class_names[i]: float(predictions[0][i]) * 100\n                     for i in range(len(class_names))}\n\n        return jsonify({\n            'success': True,\n            'prediction': {\n                'class': predicted_class,\n                'class_fa': CLASS_NAMES_FA.get(predicted_class, predicted_class),\n                'confidence': round(confidence, 2),\n                'tip': RECYCLING_TIPS.get(predicted_class, ''),\n                'all_probabilities': {k: round(v, 2) for k, v in all_probs.items()}\n            }\n        })\n    except Exception as e:\n        return jsonify({'error': str(e)}), 500\n\n\n@app.route('/download-model')\ndef download_model():\n    model_path = MODEL_PATH if os.path.exists(MODEL_PATH) else BEST_MODEL_PATH\n    if os.path.exists(model_path):\n        return send_file(model_path, as_attachment=True)\n    return jsonify({'error': 'Model not found'}), 404\n\n\n@app.route('/status')\ndef status():\n    return jsonify({\n        'server': 'running',\n        'model_loaded': model is not None,\n        'class_names': class_names\n    })\n\n\nif __name__ == '__main__':\n    load_model()\n    app.run(host='0.0.0.0', port=5000, debug=False)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ایجاد پوشه templates\nimport os\nos.makedirs('templates', exist_ok=True)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%writefile templates/index.html\n<!DOCTYPE html>\n<html lang=\"fa\" dir=\"rtl\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no\">\n    <title>طبقه‌بندی زباله | Waste Classifier</title>\n    <style>\n        * { margin: 0; padding: 0; box-sizing: border-box; }\n        body {\n            font-family: 'Segoe UI', Tahoma, Arial, sans-serif;\n            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);\n            min-height: 100vh; color: #fff; overflow-x: hidden;\n        }\n        .container { max-width: 800px; margin: 0 auto; padding: 20px; }\n        header { text-align: center; padding: 20px 0; margin-bottom: 20px; }\n        h1 { font-size: 2rem; color: #00d4ff; margin-bottom: 10px; }\n        .subtitle { color: #a0a0a0; font-size: 1rem; }\n        .camera-container {\n            position: relative; background: #1a1a2e; border-radius: 20px;\n            overflow: hidden; box-shadow: 0 10px 40px rgba(0,0,0,0.5); margin-bottom: 20px;\n        }\n        #video { width: 100%; max-height: 60vh; object-fit: cover; display: block; }\n        #canvas { display: none; }\n        .camera-overlay {\n            position: absolute; top: 0; left: 0; right: 0; bottom: 0;\n            display: flex; align-items: center; justify-content: center;\n            background: rgba(0,0,0,0.7); z-index: 10;\n        }\n        .camera-overlay.hidden { display: none; }\n        .camera-overlay p { font-size: 1.2rem; color: #00d4ff; }\n        .controls { display: flex; gap: 15px; justify-content: center; flex-wrap: wrap; margin-bottom: 20px; }\n        .btn {\n            padding: 15px 30px; font-size: 1.1rem; font-weight: bold;\n            border: none; border-radius: 50px; cursor: pointer;\n            transition: all 0.3s ease; display: flex; align-items: center; gap: 10px;\n        }\n        .btn-primary { background: linear-gradient(45deg, #00d4ff, #0099cc); color: #fff; }\n        .btn-primary:hover { transform: scale(1.05); box-shadow: 0 5px 20px rgba(0,212,255,0.5); }\n        .btn-secondary { background: linear-gradient(45deg, #4ecdc4, #2d9a93); color: #fff; }\n        .btn:disabled { opacity: 0.5; cursor: not-allowed; }\n        .result-container {\n            background: rgba(255,255,255,0.1); border-radius: 20px;\n            padding: 25px; margin-bottom: 20px; backdrop-filter: blur(10px); display: none;\n        }\n        .result-container.show { display: block; animation: fadeIn 0.5s ease; }\n        @keyframes fadeIn { from { opacity: 0; transform: translateY(20px); } to { opacity: 1; transform: translateY(0); } }\n        .result-header { text-align: center; margin-bottom: 20px; }\n        .result-class { font-size: 2rem; color: #00d4ff; margin-bottom: 10px; }\n        .result-confidence { font-size: 1.5rem; color: #4ecdc4; }\n        .result-tip {\n            background: rgba(78,205,196,0.2); padding: 15px; border-radius: 10px;\n            margin-top: 15px; border-right: 4px solid #4ecdc4;\n        }\n        .probabilities { margin-top: 20px; }\n        .prob-item { margin-bottom: 15px; }\n        .prob-label { display: flex; justify-content: space-between; margin-bottom: 5px; font-size: 0.95rem; }\n        .prob-bar { height: 12px; background: rgba(255,255,255,0.1); border-radius: 6px; overflow: hidden; }\n        .prob-fill { height: 100%; border-radius: 6px; transition: width 0.5s ease; }\n        .prob-fill.plastic { background: linear-gradient(90deg, #ff6b6b, #ff8e8e); }\n        .prob-fill.paper { background: linear-gradient(90deg, #ffd93d, #ffed4a); }\n        .prob-fill.metal { background: linear-gradient(90deg, #6c5ce7, #a29bfe); }\n        .prob-fill.organic { background: linear-gradient(90deg, #00b894, #55efc4); }\n        .loading { display: none; text-align: center; padding: 20px; }\n        .loading.show { display: block; }\n        .spinner {\n            width: 50px; height: 50px; border: 4px solid rgba(0,212,255,0.2);\n            border-top-color: #00d4ff; border-radius: 50%;\n            animation: spin 1s linear infinite; margin: 0 auto 15px;\n        }\n        @keyframes spin { to { transform: rotate(360deg); } }\n        .switch-camera {\n            position: absolute; top: 10px; left: 10px; z-index: 15;\n            background: rgba(0,0,0,0.5); border: none; color: white;\n            width: 45px; height: 45px; border-radius: 50%; font-size: 1.5rem; cursor: pointer;\n        }\n        #captured-preview { display: none; width: 100%; max-height: 60vh; object-fit: contain; }\n        #captured-preview.show { display: block; }\n        footer { text-align: center; padding: 20px; color: #666; font-size: 0.9rem; }\n        @media (max-width: 600px) { h1 { font-size: 1.5rem; } .btn { padding: 12px 20px; font-size: 1rem; } }\n    </style>\n</head>\n<body>\n    <div class=\"container\">\n        <header>\n            <h1>طبقه‌بندی زباله</h1>\n            <p class=\"subtitle\">Waste Classification with CNN</p>\n        </header>\n        <div class=\"camera-container\">\n            <div class=\"camera-overlay\" id=\"camera-overlay\"><p>در حال باز کردن دوربین...</p></div>\n            <button class=\"switch-camera\" id=\"switch-camera\" title=\"تغییر دوربین\">&#x1F504;</button>\n            <video id=\"video\" autoplay playsinline></video>\n            <canvas id=\"canvas\"></canvas>\n            <img id=\"captured-preview\" alt=\"تصویر گرفته شده\">\n        </div>\n        <div class=\"controls\">\n            <button class=\"btn btn-primary\" id=\"capture-btn\" disabled>گرفتن عکس</button>\n            <button class=\"btn btn-secondary\" id=\"retry-btn\" style=\"display:none;\">عکس جدید</button>\n        </div>\n        <div class=\"loading\" id=\"loading\"><div class=\"spinner\"></div><p>در حال تحلیل تصویر...</p></div>\n        <div class=\"result-container\" id=\"result-container\">\n            <div class=\"result-header\">\n                <div class=\"result-class\" id=\"result-class\"></div>\n                <div class=\"result-confidence\" id=\"result-confidence\"></div>\n            </div>\n            <div class=\"result-tip\" id=\"result-tip\"></div>\n            <div class=\"probabilities\" id=\"probabilities\"></div>\n        </div>\n        <footer><p>سیستم طبقه‌بندی هوشمند زباله - ساخته شده با TensorFlow</p></footer>\n    </div>\n    <script>\n        const video = document.getElementById('video');\n        const canvas = document.getElementById('canvas');\n        const capturedPreview = document.getElementById('captured-preview');\n        const captureBtn = document.getElementById('capture-btn');\n        const retryBtn = document.getElementById('retry-btn');\n        const switchCameraBtn = document.getElementById('switch-camera');\n        const cameraOverlay = document.getElementById('camera-overlay');\n        const loading = document.getElementById('loading');\n        const resultContainer = document.getElementById('result-container');\n        let stream = null;\n        let facingMode = 'environment';\n\n        async function initCamera() {\n            try {\n                if (stream) stream.getTracks().forEach(track => track.stop());\n                stream = await navigator.mediaDevices.getUserMedia({\n                    video: { facingMode: facingMode, width: { ideal: 1280 }, height: { ideal: 720 } }\n                });\n                video.srcObject = stream;\n                video.onloadedmetadata = () => { cameraOverlay.classList.add('hidden'); captureBtn.disabled = false; };\n            } catch (err) {\n                cameraOverlay.innerHTML = '<p style=\"color:#ff6b6b;\">خطا در دسترسی به دوربین</p>';\n            }\n        }\n\n        switchCameraBtn.addEventListener('click', () => {\n            facingMode = facingMode === 'environment' ? 'user' : 'environment'; initCamera();\n        });\n\n        captureBtn.addEventListener('click', () => {\n            canvas.width = video.videoWidth; canvas.height = video.videoHeight;\n            canvas.getContext('2d').drawImage(video, 0, 0);\n            const imageData = canvas.toDataURL('image/jpeg', 0.9);\n            capturedPreview.src = imageData; capturedPreview.classList.add('show');\n            video.style.display = 'none'; switchCameraBtn.style.display = 'none';\n            captureBtn.style.display = 'none'; retryBtn.style.display = 'flex';\n            resultContainer.classList.remove('show');\n            predictImage(imageData);\n        });\n\n        retryBtn.addEventListener('click', () => {\n            capturedPreview.classList.remove('show'); video.style.display = 'block';\n            switchCameraBtn.style.display = 'block'; captureBtn.style.display = 'flex';\n            retryBtn.style.display = 'none'; resultContainer.classList.remove('show');\n        });\n\n        async function predictImage(imageData) {\n            loading.classList.add('show');\n            try {\n                const response = await fetch('/predict', {\n                    method: 'POST', headers: { 'Content-Type': 'application/json' },\n                    body: JSON.stringify({ image: imageData })\n                });\n                const data = await response.json();\n                loading.classList.remove('show');\n                if (data.success) displayResult(data.prediction);\n            } catch (err) { loading.classList.remove('show'); }\n        }\n\n        function displayResult(prediction) {\n            document.getElementById('result-class').textContent = prediction.class_fa;\n            document.getElementById('result-confidence').textContent = 'اطمینان: ' + prediction.confidence + '%';\n            document.getElementById('result-tip').textContent = prediction.tip;\n            const probsContainer = document.getElementById('probabilities');\n            probsContainer.innerHTML = '<h4 style=\"margin-bottom:15px;\">احتمالات:</h4>';\n            const classLabels = { 'plastic': 'پلاستیک', 'paper': 'کاغذ', 'metal': 'فلز', 'organic': 'آلی' };\n            for (const [cls, prob] of Object.entries(prediction.all_probabilities)) {\n                probsContainer.innerHTML += '<div class=\"prob-item\"><div class=\"prob-label\"><span>' +\n                    (classLabels[cls] || cls) + '</span><span>' + prob + '%</span></div>' +\n                    '<div class=\"prob-bar\"><div class=\"prob-fill ' + cls + '\" style=\"width:' + prob + '%\"></div></div></div>';\n            }\n            resultContainer.classList.add('show');\n        }\n\n        document.addEventListener('DOMContentLoaded', () => initCamera());\n    </script>\n</body>\n</html>",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### اجرای سرور با ngrok\n\nبا اجرای سلول زیر، سرور Flask راه‌اندازی شده و یک لینک عمومی ngrok ایجاد می‌شود.\nلینک را در مرورگر گوشی خود باز کنید.\n\n> **نکته:** برای استفاده طولانی‌تر از ngrok، یک حساب رایگان در [ngrok.com](https://dashboard.ngrok.com) بسازید و auth token خود را تنظیم کنید.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# اجرای سرور Flask با تونل ngrok\nfrom pyngrok import ngrok\nimport threading\nimport time\n\n# اگر auth token دارید، خط زیر را از حالت کامنت خارج کنید:\n# ngrok.set_auth_token(\"YOUR_AUTH_TOKEN\")\n\ndef run_flask():\n    \"\"\"اجرای Flask در thread جداگانه\"\"\"\n    import app\n    app.load_model()\n    app.app.run(host='0.0.0.0', port=5000, debug=False, use_reloader=False)\n\n# شروع Flask در پس‌زمینه\nflask_thread = threading.Thread(target=run_flask, daemon=True)\nflask_thread.start()\n\n# صبر برای راه‌اندازی سرور\ntime.sleep(3)\n\n# ایجاد تونل ngrok\npublic_url = ngrok.connect(5000)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"سرور طبقه‌بندی زباله راه‌اندازی شد!\")\nprint(\"=\" * 60)\nprint(f\"\\nلینک برای گوشی موبایل:\")\nprint(f\"   {public_url}\")\nprint(\"\\nاین لینک را در مرورگر گوشی باز کنید\")\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## خلاصه\n\nدر این نوت‌بوک:\n\n1. **دیتاست TrashNet** را مستقیماً از GitHub دانلود کردیم (بدون نیاز به Kaggle)\n2. **داده‌ها را به ۴ کلاس** نگاشت کردیم: پلاستیک، کاغذ، فلز، آلی\n3. **یک مدل CNN سفارشی** با ۵ بلوک کانولوشنی از صفر ساختیم:\n   - BatchNormalization برای پایدارسازی آموزش\n   - L2 Regularization برای جلوگیری از بیش‌برازش\n   - Dropout در تمام بلوک‌ها\n   - Global Average Pooling به جای Flatten\n4. **Data Augmentation** قوی برای بهبود عملکرد\n5. **مدل را آموزش دادیم** با EarlyStopping، ModelCheckpoint و ReduceLROnPlateau\n6. **ارزیابی کامل:** ماتریس درهم‌ریختگی، گزارش طبقه‌بندی، دقت هر کلاس\n7. **اپلیکیشن وب Flask** با رابط فارسی و دسترسی از دوربین گوشی\n\n### معماری مدل:\n```\nInput (224x224x3)\n  → [Conv32 → BN → ReLU] x2 → MaxPool → Dropout(0.25)\n  → [Conv64 → BN → ReLU] x2 → MaxPool → Dropout(0.25)\n  → [Conv128 → BN → ReLU] x2 → MaxPool → Dropout(0.25)\n  → [Conv256 → BN → ReLU] x2 → MaxPool → Dropout(0.25)\n  → Conv512 → BN → ReLU → GlobalAveragePooling\n  → Dense(512) → BN → ReLU → Dropout(0.5)\n  → Dense(256) → BN → ReLU → Dropout(0.3)\n  → Dense(4, softmax)\n```",
   "metadata": {}
  }
 ]
}