# مستندات کامل پروژه طبقه‌بندی هوشمند زباله
# Smart Waste Classification using Convolutional Neural Network (CNN)

---

## ۱. معرفی پروژه

### ۱.۱ هدف
این پروژه یک سیستم طبقه‌بندی هوشمند زباله بر اساس یادگیری عمیق (Deep Learning) است که با استفاده از **شبکه عصبی کانولوشنی (CNN)** سفارشی، تصاویر زباله را به چهار دسته طبقه‌بندی می‌کند:

| کلاس | Class | نمونه‌ها |
|-------|-------|---------|
| پلاستیک | Plastic | بطری آب، کیسه پلاستیکی، ظروف یکبار مصرف |
| کاغذ | Paper | روزنامه، کاغذ A4، مقوا، دفترچه |
| فلز | Metal | قوطی نوشابه، فویل آلومینیوم، کنسرو |
| آلی | Organic | پسماند غذایی، پوست میوه، گیاهان |

### ۱.۲ کاربرد
- مدیریت هوشمند پسماند شهری
- سیستم‌های خودکار تفکیک زباله
- آموزش شهروندان برای بازیافت صحیح
- ربات‌های تفکیک زباله در کارخانه‌های بازیافت

### ۱.۳ محیط اجرا
- **Google Colab** با GPU (توصیه: T4 یا بالاتر)
- Python 3.x
- TensorFlow 2.x

### ۱.۴ ساختار فایل‌ها

```
waste_classification_colab.ipynb    ← نوت‌بوک اصلی (تمام کد در این فایل است)
│
├── [در زمان اجرا تولید می‌شوند:]
│   ├── waste_classifier_final.keras     ← مدل نهایی ذخیره‌شده
│   ├── best_waste_classifier.keras      ← بهترین مدل (checkpoint)
│   ├── class_names.json                 ← نام کلاس‌ها
│   ├── training_history.json            ← تاریخچه آموزش
│   ├── training_history.png             ← نمودار آموزش
│   ├── confusion_matrix.png             ← ماتریس درهم‌ریختگی
│   ├── predictions.png                  ← نمونه پیش‌بینی‌ها
│   ├── app.py                           ← سرور Flask
│   └── templates/
│       └── index.html                   ← رابط کاربری وب
```

---

## ۲. دیتاست

### ۲.۱ منبع
**TrashNet** - یک دیتاست عمومی از مخزن GitHub پروژه garythung/trashnet

- **لینک دانلود:** `https://github.com/garythung/trashnet/raw/master/data/dataset-resized.zip`
- **روش دانلود:** مستقیم با `wget` (بدون نیاز به Kaggle API یا حساب کاربری)
- **اندازه فایل:** حدود ۷۰ مگابایت (فشرده)

### ۲.۲ ساختار اصلی دیتاست
دیتاست TrashNet شامل **۶ کلاس** اصلی است:

| کلاس | تعداد تقریبی تصاویر |
|-------|---------------------|
| cardboard | ۴۰۳ |
| glass | ۵۰۱ |
| metal | ۴۱۰ |
| paper | ۵۹۴ |
| plastic | ۴۸۲ |
| trash | ۱۳۷ |

### ۲.۳ نگاشت (Mapping) به ۴ کلاس
از آنجا که هدف پروژه طبقه‌بندی به **۴ کلاس** است، نگاشت زیر اعمال می‌شود:

```python
class_mapping = {
    'plastic': 'plastic',       # پلاستیک → پلاستیک (بدون تغییر)
    'paper': 'paper',           # کاغذ → کاغذ (بدون تغییر)
    'metal': 'metal',           # فلز → فلز (بدون تغییر)
    'cardboard': 'organic',     # مقوا → آلی (مقوا ماده تجزیه‌پذیر است)
    'trash': 'organic'          # زباله عمومی → آلی
    # glass → حذف می‌شود (شیشه در ۴ کلاس هدف نیست)
}
```

**دلیل حذف glass:** کلاس شیشه در هیچ‌کدام از ۴ دسته هدف (پلاستیک، کاغذ، فلز، آلی) نمی‌گنجد و اضافه کردن آن به یکی از این دسته‌ها باعث نویز در آموزش می‌شود.

**دلیل اضافه کردن cardboard و trash به organic:** مقوا یک ماده آلی و تجزیه‌پذیر است. کلاس trash نیز عمدتاً شامل مواد مخلوط است که بهترین جایگزین برای آن کلاس آلی است.

### ۲.۴ تقسیم داده‌ها (Data Splitting)

```
تقسیم: 70% آموزش / 15% اعتبارسنجی / 15% تست
```

- **روش:** `sklearn.model_selection.train_test_split`
- **random_state=42:** برای تکرارپذیری نتایج
- **مرحله اول:** ۷۰٪ train و ۳۰٪ باقیمانده (`test_size=0.3`)
- **مرحله دوم:** ۳۰٪ باقیمانده به دو نیم ۱۵٪ val و ۱۵٪ test تقسیم می‌شود (`test_size=0.5`)

**نامگذاری یکتای فایل‌ها:** از آنجا که cardboard و trash هر دو به organic نگاشت می‌شوند، فایل‌ها با پیشوند نام کلاس اصلی نامگذاری می‌شوند تا تداخل نام رخ ندهد:
```
organic/
  ├── cardboard_0.jpg
  ├── cardboard_1.jpg
  ├── trash_0.jpg
  └── trash_1.jpg
```

---

## ۳. پیش‌پردازش داده‌ها (Data Preprocessing)

### ۳.۱ اندازه تصاویر
تمام تصاویر به اندازه **224 × 224 پیکسل** تغییر اندازه (Resize) می‌شوند. این اندازه:
- استاندارد برای شبکه‌های CNN است
- تعادل خوبی بین دقت و سرعت محاسبه ایجاد می‌کند
- با معماری‌های مرسوم (VGG, ResNet, EfficientNet) سازگار است

### ۳.۲ نرمال‌سازی (Normalization)
مقادیر پیکسل‌ها از بازه `[0, 255]` به بازه `[0, 1]` نرمال‌سازی می‌شوند:
```python
rescale=1./255
```
**دلیل:** شبکه‌های عصبی با مقادیر کوچک‌تر بهتر و سریع‌تر همگرا می‌شوند.

### ۳.۳ افزایش داده (Data Augmentation)
Data Augmentation **فقط** روی داده‌های آموزش (train) اعمال می‌شود و روی داده‌های اعتبارسنجی و تست اعمال **نمی‌شود**.

| پارامتر | مقدار | توضیح |
|---------|-------|-------|
| `rotation_range` | 40 | چرخش تصادفی تا ۴۰ درجه |
| `width_shift_range` | 0.2 | جابجایی افقی تا ۲۰٪ عرض |
| `height_shift_range` | 0.2 | جابجایی عمودی تا ۲۰٪ ارتفاع |
| `shear_range` | 0.2 | تبدیل برشی (Shear) تا ۲۰٪ |
| `zoom_range` | 0.2 | بزرگنمایی/کوچک‌نمایی تا ۲۰٪ |
| `horizontal_flip` | True | آینه کردن افقی تصادفی |
| `vertical_flip` | True | آینه کردن عمودی تصادفی |
| `fill_mode` | 'nearest' | پر کردن پیکسل‌های خالی با نزدیک‌ترین پیکسل |

**هدف Data Augmentation:** افزایش مجازی تعداد داده‌های آموزش بدون نیاز به جمع‌آوری داده جدید. هر بار که یک تصویر به مدل داده می‌شود، یک نسخه تغییر یافته تصادفی از آن ارائه می‌شود. این کار:
- از **بیش‌برازش (Overfitting)** جلوگیری می‌کند
- مدل را نسبت به **تغییرات زاویه، اندازه و موقعیت** مقاوم می‌کند
- **تعمیم‌پذیری (Generalization)** مدل را بهبود می‌بخشد

### ۳.۴ Batch Size
```python
BATCH_SIZE = 32
```
در هر مرحله آموزش، ۳۲ تصویر به‌صورت همزمان پردازش می‌شوند. این مقدار تعادل خوبی بین سرعت آموزش و مصرف حافظه GPU ایجاد می‌کند.

---

## ۴. معماری مدل CNN

### ۴.۱ نمای کلی
مدل یک **CNN سفارشی** است که از صفر (from scratch) ساخته شده و از هیچ مدل از پیش آموزش‌دیده‌ای (Pre-trained Model) استفاده **نمی‌کند**.

```
ورودی: تصویر 224×224×3 (RGB)
    ↓
بلوک ۱: [Conv2D(32) → BN → ReLU] × 2 → MaxPool → Dropout(0.25)
    ↓
بلوک ۲: [Conv2D(64) → BN → ReLU] × 2 → MaxPool → Dropout(0.25)
    ↓
بلوک ۳: [Conv2D(128) → BN → ReLU] × 2 → MaxPool → Dropout(0.25)
    ↓
بلوک ۴: [Conv2D(256) → BN → ReLU] × 2 → MaxPool → Dropout(0.25)
    ↓
بلوک ۵: Conv2D(512) → BN → ReLU
    ↓
Global Average Pooling 2D
    ↓
Dense(512) → BN → ReLU → Dropout(0.5)
    ↓
Dense(256) → BN → ReLU → Dropout(0.3)
    ↓
Dense(4, softmax) → خروجی: احتمال هر کلاس
```

### ۴.۲ توضیح لایه‌ها

#### Conv2D (لایه کانولوشنی)
```python
layers.Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(0.001))
```
- **فیلترها:** تعداد فیلترهای کانولوشنی (32, 64, 128, 256, 512) که به‌ترتیب افزایش می‌یابند
- **اندازه کرنل:** `(3, 3)` - پنجره ۳×۳ برای اسکن تصویر
- **padding='same':** اندازه خروجی برابر اندازه ورودی نگه داشته می‌شود (با اضافه کردن صفر در حاشیه). بدون این پارامتر، هر لایه کانولوشنی اندازه تصویر را ۲ پیکسل کاهش می‌دهد
- **kernel_regularizer=l2(0.001):** جریمه L2 روی وزن‌ها برای جلوگیری از بیش‌برازش. مقدار 0.001 یعنی ۰.۱٪ مجموع مربعات وزن‌ها به تابع خطا اضافه می‌شود

**نقش لایه‌های کانولوشنی:**
- بلوک‌های اولیه (32, 64): استخراج ویژگی‌های سطح پایین مثل **لبه‌ها، خطوط، بافت‌ها**
- بلوک‌های میانی (128, 256): استخراج ویژگی‌های سطح متوسط مثل **اشکال، الگوها**
- بلوک آخر (512): استخراج ویژگی‌های سطح بالا مثل **اشیاء کامل، ترکیب‌بندی**

#### BatchNormalization (نرمال‌سازی دسته‌ای)
```python
layers.BatchNormalization()
```
- خروجی هر لایه را نرمال‌سازی می‌کند (میانگین نزدیک به ۰ و واریانس نزدیک به ۱)
- **مزایا:**
  - آموزش سریع‌تر و پایدارتر
  - امکان استفاده از نرخ یادگیری بزرگ‌تر
  - عمل به عنوان یک نوع Regularization
- **محل قرارگیری:** بعد از Conv2D و قبل از Activation (ReLU)

#### Activation('relu') (تابع فعال‌سازی)
```python
layers.Activation('relu')
```
- **ReLU (Rectified Linear Unit):** `f(x) = max(0, x)`
- مقادیر منفی را صفر و مقادیر مثبت را بدون تغییر عبور می‌دهد
- **دلیل استفاده:** غیرخطی بودن شبکه را تضمین می‌کند. بدون تابع فعال‌سازی غیرخطی، کل شبکه معادل یک تبدیل خطی واحد خواهد بود
- **مزیت ReLU نسبت به sigmoid/tanh:** محاسبه سریع‌تر و عدم مشکل ناپدید شدن گرادیان (Vanishing Gradient)

#### MaxPooling2D (ادغام بیشینه)
```python
layers.MaxPooling2D((2, 2))
```
- اندازه نقشه ویژگی (Feature Map) را به نصف کاهش می‌دهد
- از هر پنجره ۲×۲، بیشترین مقدار را انتخاب می‌کند
- **مزایا:** کاهش ابعاد → کاهش محاسبات → ایجاد مقاومت مکانی (Spatial Invariance)

**تغییرات ابعاد در هر بلوک:**
```
ورودی: 224×224 → بلوک ۱: 112×112 → بلوک ۲: 56×56 → بلوک ۳: 28×28 → بلوک ۴: 14×14
```

#### Dropout (حذف تصادفی)
```python
layers.Dropout(0.25)    # در بلوک‌های کانولوشنی
layers.Dropout(0.5)     # در لایه Dense اول
layers.Dropout(0.3)     # در لایه Dense دوم
```
- در هر مرحله آموزش، درصد مشخصی از نورون‌ها به‌صورت تصادفی غیرفعال می‌شوند
- **0.25 = 25%** نورون‌ها در بلوک‌های کانولوشنی
- **0.5 = 50%** نورون‌ها در لایه Dense اول (شدیدتر چون تعداد پارامترها بیشتر است)
- **0.3 = 30%** نورون‌ها در لایه Dense دوم
- **هدف:** جلوگیری از بیش‌برازش با مجبور کردن شبکه به یادگیری ویژگی‌های مقاوم‌تر
- **نکته:** Dropout فقط در زمان آموزش فعال است و در زمان پیش‌بینی غیرفعال می‌شود

#### GlobalAveragePooling2D (ادغام میانگین سراسری)
```python
layers.GlobalAveragePooling2D()
```
- از هر نقشه ویژگی ۱۴×۱۴ (خروجی بلوک ۴)، **میانگین** تمام مقادیر را حساب می‌کند
- خروجی: یک بردار ۵۱۲ بعدی (یک عدد برای هر فیلتر)
- **مقایسه با Flatten:**
  - `Flatten` خروجی ۱۴×۱۴×۵۱۲ = **100,352** عدد تولید می‌کند
  - `GlobalAveragePooling2D` فقط **512** عدد تولید می‌کند
- **مزایا:** تعداد پارامترها به شدت کاهش → کمتر مستعد بیش‌برازش + مقاومت مکانی بیشتر

#### Dense (لایه‌های تمام‌متصل)
```python
layers.Dense(512, kernel_regularizer=l2(0.001))    # لایه پنهان اول
layers.Dense(256, kernel_regularizer=l2(0.001))    # لایه پنهان دوم
layers.Dense(4, activation='softmax')               # لایه خروجی
```
- **Dense(512):** ویژگی‌های استخراج شده از بلوک‌های کانولوشنی را ترکیب می‌کند
- **Dense(256):** تعداد ویژگی‌ها را به‌تدریج کاهش می‌دهد
- **Dense(4, softmax):** لایه خروجی با ۴ نورون (یکی برای هر کلاس)
  - **softmax:** احتمالات خروجی را طوری نرمال‌سازی می‌کند که مجموع آن‌ها برابر ۱ باشد
  - مثال خروجی: `[0.05, 0.02, 0.03, 0.90]` → ۹۰٪ احتمال آلی

### ۴.۳ L2 Regularization (منظم‌سازی L2)
```python
kernel_regularizer=l2(0.001)
```
- روی **تمام** لایه‌های Conv2D و Dense اعمال شده
- عبارت `0.001 × Σ(w²)` به تابع خطا اضافه می‌شود
- مدل را تشویق به استفاده از وزن‌های کوچک‌تر می‌کند → پیچیدگی مدل کنترل می‌شود → بیش‌برازش کمتر

### ۴.۴ خلاصه تکنیک‌های مقابله با بیش‌برازش
این مدل از **۴ تکنیک همزمان** برای جلوگیری از Overfitting استفاده می‌کند:

| تکنیک | محل اعمال | نحوه عملکرد |
|-------|----------|-------------|
| Data Augmentation | داده‌های آموزش | افزایش تنوع داده‌ها |
| Dropout | بعد از هر بلوک و Dense | حذف تصادفی نورون‌ها |
| L2 Regularization | تمام Conv2D و Dense | جریمه وزن‌های بزرگ |
| BatchNormalization | بعد از هر Conv2D و Dense | نرمال‌سازی فعال‌سازی‌ها |

---

## ۵. آموزش مدل (Training)

### ۵.۱ تنظیمات کامپایل
```python
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)
```

- **Adam Optimizer:** بهینه‌ساز تطبیقی که نرخ یادگیری را برای هر پارامتر به‌صورت جداگانه تنظیم می‌کند. ترکیبی از مزایای Momentum و RMSProp
- **learning_rate=0.001:** نرخ یادگیری اولیه. هر بار وزن‌ها به اندازه ۰.۱٪ گرادیان تغییر می‌کنند
- **categorical_crossentropy:** تابع خطا برای مسائل طبقه‌بندی چندکلاسه. اختلاف بین توزیع احتمال پیش‌بینی و واقعی را اندازه‌گیری می‌کند
- **accuracy:** معیار ارزیابی - درصد پیش‌بینی‌های صحیح

### ۵.۲ Callback ها (توابع فراخوانی)

#### EarlyStopping (توقف زودهنگام)
```python
EarlyStopping(
    monitor='val_loss',
    patience=15,
    restore_best_weights=True
)
```
- **monitor='val_loss':** خطای اعتبارسنجی را زیر نظر می‌گیرد
- **patience=15:** اگر ۱۵ epoch متوالی خطای اعتبارسنجی بهبود پیدا نکند، آموزش متوقف می‌شود
- **restore_best_weights=True:** وزن‌های بهترین epoch (نه آخرین epoch) بازیابی می‌شود
- **هدف:** جلوگیری از آموزش بیش از حد و صرفه‌جویی در زمان

#### ModelCheckpoint (ذخیره مدل)
```python
ModelCheckpoint(
    'best_waste_classifier.keras',
    monitor='val_accuracy',
    save_best_only=True
)
```
- **monitor='val_accuracy':** دقت اعتبارسنجی را زیر نظر می‌گیرد
- **save_best_only=True:** فقط وقتی مدل بهتر از قبل شود ذخیره می‌کند
- **فرمت .keras:** فرمت جدید و توصیه‌شده TensorFlow برای ذخیره مدل

#### ReduceLROnPlateau (کاهش نرخ یادگیری)
```python
ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=5,
    min_lr=1e-7
)
```
- **factor=0.5:** نرخ یادگیری را نصف می‌کند (مثلاً 0.001 → 0.0005)
- **patience=5:** بعد از ۵ epoch بدون بهبود خطای اعتبارسنجی
- **min_lr=1e-7:** حداقل نرخ یادگیری (0.0000001)
- **هدف:** وقتی مدل به حداقل محلی نزدیک می‌شود، نرخ یادگیری کوچک‌تر باعث دقت بیشتر در رسیدن به بهینه می‌شود

### ۵.۳ پارامترهای آموزش
```python
EPOCHS = 50  # حداکثر تعداد دوره‌های آموزش
```
- **EPOCHS=50:** حداکثر ۵۰ بار تمام داده‌های آموزش به مدل نمایش داده می‌شود
- در عمل، EarlyStopping معمولاً آموزش را قبل از ۵۰ epoch متوقف می‌کند

---

## ۶. ارزیابی مدل (Evaluation)

### ۶.۱ معیارهای ارزیابی

#### Accuracy (دقت کلی)
- درصد پیش‌بینی‌های صحیح از کل پیش‌بینی‌ها
- `دقت = تعداد پیش‌بینی‌های صحیح / تعداد کل نمونه‌ها`

#### Classification Report
برای هر کلاس سه معیار محاسبه می‌شود:

| معیار | فرمول | توضیح |
|-------|-------|-------|
| **Precision** (دقت) | TP / (TP + FP) | از تمام نمونه‌هایی که مدل گفته «پلاستیک»، چند درصد واقعاً پلاستیک بوده؟ |
| **Recall** (فراخوانی) | TP / (TP + FN) | از تمام پلاستیک‌های واقعی، مدل چند درصد را درست تشخیص داده؟ |
| **F1-Score** | 2 × (P × R) / (P + R) | میانگین هارمونیک Precision و Recall |

- **TP (True Positive):** پیش‌بینی صحیح مثبت
- **FP (False Positive):** پیش‌بینی غلط مثبت (مدل اشتباهاً گفته مثبت)
- **FN (False Negative):** پیش‌بینی غلط منفی (مدل اشتباهاً گفته منفی)

#### Confusion Matrix (ماتریس درهم‌ریختگی)
- جدول دوبعدی که سطرها = برچسب واقعی و ستون‌ها = برچسب پیش‌بینی‌شده
- اعداد روی قطر اصلی = پیش‌بینی‌های صحیح
- اعداد خارج قطر = اشتباهات مدل
- **رنگ آبی تیره‌تر = تعداد بیشتر**

---

## ۷. پیش‌بینی تصویر جدید (Inference)

### ۷.۱ مراحل پیش‌پردازش یک تصویر جدید
```python
# ۱. بارگذاری تصویر و تغییر اندازه به 224×224
img = image.load_img(img_path, target_size=(224, 224))

# ۲. تبدیل به آرایه numpy
img_array = image.img_to_array(img)

# ۳. نرمال‌سازی به بازه [0, 1]
img_array = img_array / 255.0

# ۴. اضافه کردن بعد batch (مدل انتظار ورودی 4 بعدی دارد)
img_array = np.expand_dims(img_array, axis=0)
# شکل نهایی: (1, 224, 224, 3)
```

### ۷.۲ تفسیر خروجی
خروجی مدل یک بردار ۴ عددی است:
```
[0.05, 0.02, 0.03, 0.90]
  ↑      ↑      ↑      ↑
metal  organic paper  plastic
```
- هر عدد نشان‌دهنده **احتمال** تعلق تصویر به آن کلاس است
- مجموع اعداد = ۱ (تابع softmax)
- **کلاس نهایی:** کلاس با بیشترین احتمال (`np.argmax`)
- **اطمینان:** بیشترین مقدار احتمال × ۱۰۰ (به درصد)

---

## ۸. اپلیکیشن وب Flask

### ۸.۱ معماری سیستم
```
[مرورگر گوشی] ←→ [ngrok تونل] ←→ [Flask سرور] ←→ [مدل TensorFlow]
     │                                    │
     │  ۱. عکس از دوربین               ۳. پیش‌بینی
     │  ۲. ارسال base64               ۴. JSON نتیجه
     └────────────────────────────────────┘
```

### ۸.۲ سرور Flask (app.py)

#### مسیرها (Routes):

| مسیر | متد | عملکرد |
|------|-----|--------|
| `/` | GET | صفحه اصلی HTML با رابط دوربین |
| `/predict` | POST | دریافت تصویر base64، پیش‌بینی، برگرداندن JSON |
| `/download-model` | GET | دانلود فایل مدل .keras |
| `/status` | GET | وضعیت سرور و مدل |

#### جریان پیش‌بینی (`/predict`):
1. دریافت JSON با کلید `image` حاوی تصویر base64
2. حذف هدر `data:image/jpeg;base64,` از رشته base64
3. دیکد base64 به بایت
4. باز کردن با PIL و تبدیل به RGB
5. تغییر اندازه به 224×224
6. نرمال‌سازی به [0, 1]
7. پیش‌بینی با مدل
8. برگرداندن JSON شامل: نام کلاس (انگلیسی + فارسی)، درصد اطمینان، نکته بازیافت، احتمال هر کلاس

### ۸.۳ رابط کاربری HTML

#### ویژگی‌ها:
- **RTL (راست به چپ):** کامل فارسی
- **طراحی واکنش‌گرا (Responsive):** سازگار با موبایل و دسکتاپ
- **تم تیره:** پس‌زمینه گرادیان تیره با رنگ‌های آبی فیروزه‌ای
- **دسترسی به دوربین:** از API مرورگر `navigator.mediaDevices.getUserMedia`
- **تغییر دوربین:** دکمه تعویض بین دوربین جلو و عقب (`facingMode: 'environment' | 'user'`)

#### جریان کار کاربر:
1. باز کردن لینک ngrok در مرورگر گوشی
2. اجازه دسترسی به دوربین
3. قرار دادن زباله جلوی دوربین
4. زدن دکمه «گرفتن عکس»
5. مشاهده نتیجه: نام کلاس فارسی + درصد اطمینان + نوار احتمالات + نکته بازیافت
6. زدن «عکس جدید» برای تست بعدی

### ۸.۴ ngrok (تونل شبکه)
- **مشکل:** Google Colab IP عمومی ندارد و مستقیماً از گوشی قابل دسترسی نیست
- **راه‌حل:** `pyngrok` یک تونل HTTPS عمومی ایجاد می‌کند
- **مزیت HTTPS:** دوربین مرورگر فقط روی HTTPS کار می‌کند (مخصوصاً iOS Safari)

```python
# Flask در یک thread جداگانه اجرا می‌شود تا نوت‌بوک بلاک نشود
flask_thread = threading.Thread(target=run_flask, daemon=True)
flask_thread.start()

# ngrok تونل عمومی ایجاد می‌کند
public_url = ngrok.connect(5000)
# خروجی: https://xxxx-xx-xx-xx-xx.ngrok-free.app
```

---

## ۹. وابستگی‌ها (Dependencies)

| کتابخانه | نسخه حداقل | کاربرد |
|----------|-----------|--------|
| TensorFlow | >= 2.10 | فریم‌ورک اصلی یادگیری عمیق |
| NumPy | >= 1.21 | عملیات آرایه‌ای و ماتریسی |
| Matplotlib | - | رسم نمودارها و نمایش تصاویر |
| Scikit-learn | - | تقسیم داده، گزارش طبقه‌بندی، ماتریس درهم‌ریختگی |
| Seaborn | - | نمایش هیت‌مپ ماتریس درهم‌ریختگی |
| Pillow (PIL) | >= 9.0 | پردازش تصویر در سرور Flask |
| Flask | >= 2.0 | فریم‌ورک وب سبک‌وزن |
| pyngrok | - | تونل ngrok برای دسترسی عمومی |

---

## ۱۰. نحوه اجرا

### مرحله ۱: آماده‌سازی محیط
1. فایل `waste_classification_colab.ipynb` را در Google Colab آپلود کنید
2. از منوی **Runtime > Change runtime type** گزینه **GPU** (ترجیحاً T4) را انتخاب کنید

### مرحله ۲: اجرای نوت‌بوک
- **Runtime > Run all** را بزنید
- یا سلول به سلول با **Shift+Enter** اجرا کنید

### مرحله ۳: مشاهده نتایج
- بعد از اتمام آموزش، نمودارها و ارزیابی‌ها خودکار نمایش داده می‌شوند
- فایل‌های مدل و نتایج به‌صورت خودکار دانلود می‌شوند

### مرحله ۴: تست با گوشی (اختیاری)
- سلول‌های بخش ۱۲ (Flask) را اجرا کنید
- لینک ngrok نمایش داده شده را در مرورگر گوشی باز کنید
- از دوربین برای تست زنده استفاده کنید

---

## ۱۱. خروجی‌های پروژه

| فایل | توضیح |
|------|-------|
| `waste_classifier_final.keras` | مدل نهایی آموزش‌دیده (قابل استفاده در اپلیکیشن‌های موبایل/وب) |
| `best_waste_classifier.keras` | بهترین مدل ذخیره‌شده توسط ModelCheckpoint |
| `class_names.json` | لیست نام کلاس‌ها: `["metal", "organic", "paper", "plastic"]` |
| `training_history.json` | مقادیر accuracy و loss هر epoch |
| `training_history.png` | نمودار تغییرات accuracy و loss در طول آموزش |
| `confusion_matrix.png` | ماتریس درهم‌ریختگی روی داده تست |
| `predictions.png` | نمونه پیش‌بینی‌های مدل با برچسب واقعی |
